# Heavy-Read API Benchmark Report

**Generated:** 2025-11-29 13:39:14 UTC

## Hardware & Configuration

| Component | Details |
|-----------|---------|
| **CPU Model** | Apple M3 Pro |
| **CPU Cores** | 11 |
| **Memory (RAM)** | 18 GB |
| **Go Version** | go1.25.3 |
| **Redis Version** |  |
| **wrk Version** | wrk 4.2.0 [kqueue] Copyright (C) 2012 Will Glozer |

### wrk Configuration

| Parameter | Value |
|-----------|-------|
| Threads | 4 |
| Connections | 400 |
| Duration | 10s |

---

## Direct Connection (http://localhost:8081)

### Latency Comparison

| Metric | /post-redis | /post-marshal | /post (Optimized) | Improvement vs Redis | Improvement vs Marshal |
|--------|-------------|---------------|-------------------|---------------------|------------------------|
| **P50 Latency** | 7.01 ms | 5.16 ms | 4.98 ms | 1.4x faster | 1.0x faster |
| **P90 Latency** | 11.89 ms | 7.95 ms | 7.52 ms | 1.5x faster | 1.0x faster |
| **P99 Latency** | 27.26 ms | 14.40 ms | 12.50 ms | 2.1x faster | 1.1x faster |
| **Avg Latency** | 8.05 ms | 5.60 ms | 5.35 ms | 1.5x faster | 1.0x faster |
| **Max Latency** | 85.29 ms | 34.53 ms | 31.74 ms | 2.6x faster | 1.0x faster |
| **Stdev** | 5.07 ms | 2.31 ms | 1.97 ms | - | - |

### Throughput Comparison

| Metric | /post-redis | /post-marshal | /post (Optimized) | Improvement vs Redis | Improvement vs Marshal |
|--------|-------------|---------------|-------------------|---------------------|------------------------|
| **Requests/sec** | 51806.86 | 71890.71 | 74719.59 | 1.4x higher | 1.0x higher |
| **Transfer/sec** | 19168.56 KB | 26399.32 KB | 27399.95 KB | - | - |
| **Total Requests** | 518345 | 719418 | 747815 | - | - |
| **Total Errors** | 0 | 0 | 0 | - | - |

---

## Via APISIX Gateway (http://localhost:9080)

### Latency Comparison

| Metric | /post-redis | /post-marshal | /post (Optimized) | Improvement vs Redis | Improvement vs Marshal |
|--------|-------------|---------------|-------------------|---------------------|------------------------|
| **P50 Latency** | 9.57 ms | 8.33 ms | 8.30 ms | 1.1x faster | 1.0x faster |
| **P90 Latency** | 21.63 ms | 21.40 ms | 20.58 ms | 1.0x faster | 1.0x faster |
| **P99 Latency** | 44.98 ms | 48.43 ms | 45.02 ms | .9x faster | 1.0x faster |
| **Avg Latency** | 11.79 ms | 11.02 ms | 10.79 ms | 1.0x faster | 1.0x faster |
| **Max Latency** | 120.49 ms | 110.74 ms | 146.70 ms | .8x faster | .7x faster |
| **Stdev** | 8.62 ms | 9.36 ms | 9.19 ms | - | - |

### Throughput Comparison

| Metric | /post-redis | /post-marshal | /post (Optimized) | Improvement vs Redis | Improvement vs Marshal |
|--------|-------------|---------------|-------------------|---------------------|------------------------|
| **Requests/sec** | 36777.56 | 41056.42 | 41568.58 | 1.1x higher | 1.0x higher |
| **Transfer/sec** | 17109.75 KB | 19008.04 KB | 19221.28 KB | - | - |
| **Total Requests** | 368222 | 410790 | 415947 | - | - |
| **Total Errors** | 0 | 0 | 0 | - | - |

---

## Endpoint Descriptions

| Endpoint | Description |
|----------|-------------|
| **/post** | Optimized endpoint using `OnSetLocalCache` callback with pre-processed `CachedPost` wrapper (zero CPU-bound operations on read path) |
| **/post-redis** | Endpoint that fetches directly from Redis on every request (bypasses local cache) |
| **/post-marshal** | Endpoint that uses local cache but re-marshals the cached data to JSON on every request |

## Key Insights

1. **Local Cache Advantage**: The optimized `/post` endpoint eliminates all serialization overhead by storing pre-processed data in local cache
2. **Redis Latency**: Direct Redis fetches add significant network latency compared to local cache hits
3. **Marshal Overhead**: JSON marshalling on every request adds CPU overhead even with local cache
4. **APISIX Overhead**: The gateway adds consistent latency overhead but preserves relative performance differences

---

*Report generated by run_benchmark.sh*
